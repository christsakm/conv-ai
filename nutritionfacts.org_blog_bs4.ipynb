# This piece of code word wraps the output text
from IPython.display import HTML, display

def set_css():
  display(HTML('''<style> pre { white-space: pre-wrap; } </style>'''))
get_ipython().events.register('pre_run_cell', set_css)

!pip install beautifulsoup4

import requests
from bs4 import BeautifulSoup

blog_months = []
blog_articles = []

req = requests.get("https://nutritionfacts.org/blog/")
# print(req.content)
soup = BeautifulSoup(req.content, "html.parser")
# print(soup.prettify())
archives = soup.select("select option") # ARCHIVE SELECTOR
# print(archives)
for option in archives:
  if option.get('value').startswith('http'):
    # print(option.get('value'))
    blog_months.append(option.get('value'))

for blog_month in blog_months:
  req = requests.get(blog_month)
  soup = BeautifulSoup(req.content, "html.parser")
  # print(soup.prettify())
  blog_posts = soup.select(".entry-title > a") # BLOG POST SELECTOR
  # print(blog_posts)
  for blog_post in blog_posts:
    # print(blog_post.get('href'), blog_post.get('title'))
    blog_articles.append({
      "title" : blog_post.get('title'), 
      "link" : blog_post.get('href')
    })
# blog_articles

!mkdir blog_posts_downloaded
# print(len(blog_articles))
for i in range(len(blog_articles)):
  title = blog_articles[i]["title"]
  title = title.replace('/',' ') # sanitize title
  link = blog_articles[i]["link"]
  with open('blog_posts_downloaded/' + title + '.html', 'w') as file:
    req = requests.get(link)
    soup = BeautifulSoup(req.content, "html.parser")
    file.write(soup.prettify())

!zip -r blog_posts_downloaded blog_posts_downloaded
from google.colab import files
files.download("blog_posts_downloaded.zip")
